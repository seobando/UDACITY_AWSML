{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mahalanobis_similarity(vector1, vector2, inv_covariance_matrix):\n",
    "    diff = vector1 - vector2\n",
    "    distance = np.sqrt(diff.dot(inv_covariance_matrix).dot(diff))\n",
    "    return np.exp(-distance)\n",
    "\n",
    "def get_recommendations(user_profile, train_data, k=5):\n",
    "    covariance_matrix = np.cov(train_data.values.T)\n",
    "    inv_covariance_matrix = np.linalg.inv(covariance_matrix)\n",
    "    \n",
    "    similarities = np.array([\n",
    "        calculate_mahalanobis_similarity(\n",
    "            user_profile.iloc[0].values,\n",
    "            train_data.iloc[i].values,\n",
    "            inv_covariance_matrix\n",
    "        )\n",
    "        for i in range(len(train_data))\n",
    "    ])\n",
    "    \n",
    "    similar_indices = np.argsort(similarities)[-k:]\n",
    "    return train_data.iloc[similar_indices], similarities[similar_indices]\n",
    "\n",
    "def fill_test_values(test_data, train_data):\n",
    "    filled_predictions = test_data.copy()\n",
    "    \n",
    "    for idx in range(len(test_data)):\n",
    "        test_user = test_data.iloc[[idx]]\n",
    "        similar_users, similarities = get_recommendations(test_user, train_data)\n",
    "        \n",
    "        # Normalize similarities to weights\n",
    "        weights = similarities / np.sum(similarities)\n",
    "        weighted_predictions = np.average(similar_users, weights=weights, axis=0)\n",
    "        filled_predictions.iloc[idx] = np.round(weighted_predictions)\n",
    "    \n",
    "    return filled_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "def calculate_accuracy_metrics(evaluation, threshold=0.5):\n",
    "    y_true = evaluation['score'] >= threshold\n",
    "    y_pred = evaluation['prediction'] >= threshold\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "def calculate_error_metrics(evaluation):\n",
    "    y_true = evaluation['score']\n",
    "    y_pred = evaluation['prediction']\n",
    "    \n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    return mae, rmse\n",
    "\n",
    "def calculate_ranking_metrics(evaluation):\n",
    "    def average_precision(y_true, y_pred):\n",
    "        sorted_indices = np.argsort(y_pred)[::-1]\n",
    "        y_true_sorted = np.array(y_true)[sorted_indices]\n",
    "        cumsum = np.cumsum(y_true_sorted)\n",
    "        precision_at_k = cumsum / (np.arange(len(y_true_sorted)) + 1)\n",
    "        return np.sum(precision_at_k * y_true_sorted) / np.sum(y_true_sorted)\n",
    "    \n",
    "    def ndcg(y_true, y_pred, k=10):\n",
    "        sorted_indices = np.argsort(y_pred)[::-1]\n",
    "        y_true_sorted = np.array(y_true)[sorted_indices]\n",
    "        dcg = np.sum((2**y_true_sorted - 1) / np.log2(np.arange(1, len(y_true_sorted) + 1) + 1))\n",
    "        ideal_sorted_indices = np.argsort(y_true)[::-1]\n",
    "        y_true_ideal_sorted = np.array(y_true)[ideal_sorted_indices]\n",
    "        idcg = np.sum((2**y_true_ideal_sorted - 1) / np.log2(np.arange(1, len(y_true_ideal_sorted) + 1) + 1))\n",
    "        return dcg / idcg\n",
    "    \n",
    "    y_true = evaluation['score']\n",
    "    y_pred = evaluation['prediction']\n",
    "    \n",
    "    map_score = average_precision(y_true, y_pred)\n",
    "    ndcg_score = ndcg(y_true, y_pred)\n",
    "    \n",
    "    return map_score, ndcg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile_id</th>\n",
       "      <th>offer</th>\n",
       "      <th>score</th>\n",
       "      <th>customer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>406b1422299944039e05c12a48dba84a</td>\n",
       "      <td>discount-web-email-mobile</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3f62dc31f11b453a9909809e20852450</td>\n",
       "      <td>bogo-email-mobile-social</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>665b6493546141518af2f3a0bf316800</td>\n",
       "      <td>discount-web-email-mobile</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35c863d477084f7fb46e4b309cf3ea5d</td>\n",
       "      <td>discount-web-email-mobile</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0a947767586e4587b06b8ca3efc3c8e7</td>\n",
       "      <td>bogo-web-email-mobile-social</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         profile_id                         offer  score  \\\n",
       "0  406b1422299944039e05c12a48dba84a     discount-web-email-mobile    1.0   \n",
       "1  3f62dc31f11b453a9909809e20852450      bogo-email-mobile-social    1.0   \n",
       "2  665b6493546141518af2f3a0bf316800     discount-web-email-mobile    1.0   \n",
       "3  35c863d477084f7fb46e4b309cf3ea5d     discount-web-email-mobile    1.0   \n",
       "4  0a947767586e4587b06b8ca3efc3c8e7  bogo-web-email-mobile-social    0.0   \n",
       "\n",
       "   customer_type  \n",
       "0              1  \n",
       "1              2  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"../../data/train/user_item.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profile_id</th>\n",
       "      <th>offer</th>\n",
       "      <th>score</th>\n",
       "      <th>customer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fcbcd28beee1457f8b3672658ea0a1e3</td>\n",
       "      <td>informational-email-mobile-social</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1698291a4a474d84b7d7fc2e24ab684a</td>\n",
       "      <td>informational-email-mobile-social</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>639314daa82a46558c17020fd84d03f6</td>\n",
       "      <td>bogo-email-mobile-social</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f626cb1552414edab2afdbf0c32c8476</td>\n",
       "      <td>bogo-web-email-mobile</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61c9306f27f9423d9630b95cf66c266d</td>\n",
       "      <td>discount-web-email-mobile-social</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         profile_id                              offer  score  \\\n",
       "0  fcbcd28beee1457f8b3672658ea0a1e3  informational-email-mobile-social    1.0   \n",
       "1  1698291a4a474d84b7d7fc2e24ab684a  informational-email-mobile-social    1.0   \n",
       "2  639314daa82a46558c17020fd84d03f6           bogo-email-mobile-social    1.0   \n",
       "3  f626cb1552414edab2afdbf0c32c8476              bogo-web-email-mobile    1.0   \n",
       "4  61c9306f27f9423d9630b95cf66c266d   discount-web-email-mobile-social    1.0   \n",
       "\n",
       "   customer_type  \n",
       "0              4  \n",
       "1              1  \n",
       "2              1  \n",
       "3              3  \n",
       "4              0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"../../data/test/user_item.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_item = train[['profile_id', 'offer', 'score']]\n",
    "train_data_df = train_user_item.groupby(['profile_id', 'offer'])['score'].max().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_item = test[['profile_id', 'offer', 'score']]\n",
    "test_data_df = test_user_item.groupby(['profile_id', 'offer'])['score'].max().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predicted = fill_test_values(test_data_df, train_data_df)\n",
    "predicted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = predicted.reset_index().melt(\n",
    "    id_vars=['profile_id'], \n",
    "    var_name='offer', \n",
    "    value_name='score'\n",
    ").rename(columns={'score': 'prediction'})\n",
    "\n",
    "predicted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = pd.merge(\n",
    "    predicted, \n",
    "    test, \n",
    "    on=[\"profile_id\", \"offer\"], \n",
    "    how=\"inner\"\n",
    ").drop(columns=[\"customer_type\"])\n",
    "\n",
    "evaluation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.to_csv(\"../../data/predictions/cf_ms.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = pd.read_csv('../../data/predictions/cf_ms.csv')\n",
    "\n",
    "# Calculate accuracy metrics\n",
    "precision, recall, f1 = calculate_accuracy_metrics(evaluation)\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-Score: {f1}')\n",
    "\n",
    "# Calculate error metrics\n",
    "mae, rmse = calculate_error_metrics(evaluation)\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "\n",
    "# Calculate ranking metrics\n",
    "map_score, ndcg_score = calculate_ranking_metrics(evaluation)\n",
    "print(f'Mean Average Precision (MAP): {map_score}')\n",
    "print(f'Normalized Discounted Cumulative Gain (NDCG): {ndcg_score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
